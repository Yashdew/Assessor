{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHATISTICS GitHub Live URL Dec 202 Feb 2021 open source WhatsApp chats analyser and statistics. pplication, which provides various meaningful insights Time complexity reduces from 20 seconds. to 5 seconds. Used Flask for implementing backend REST APIs with firebase database for analysis of traffic Pandas for data pre processing Used Next JS and Bulma UI for frontend. 500+ users and 30 stars on GitHub ATTENDANCE TRACKER GitHub Live URL July 202 ug 202 A full stack web application for monitoring the attendance in Microsoft Teams from logs file of the meeting. ( Sample Optimization of code took around 3 seconds in Data pre processing. Worked on building the major backend p art and frontend Used Flask for implementing Backend and HTML, CSS & JS for frontend Used Mongo DB and Google sheet API for Database. Data pre processing of large logs files for calculating time stamps of students using pandas 50+ users in our college.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import nltk\n",
    "def getProjects(fileName):\n",
    "    \n",
    "    pdfFileObj = open(fileName, 'rb')\n",
    "    pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "    \n",
    "    text = \"\"\n",
    "    numPage = pdfReader.numPages\n",
    "    pages = 0\n",
    "    for pages in range(numPage):\n",
    "        page = pdfReader.getPage(pages).extractText()\n",
    "        text = text + page + \" \"\n",
    "    #nltk.download('punkt')\n",
    "    \n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    \n",
    "    corpus = []\n",
    "    for x in sentences:\n",
    "        corpus.append(x.replace(\"\\n\",\"\"))\n",
    "\n",
    "    formatted_text = []\n",
    "    imp_headings = ['projects']\n",
    "    excluded_headings = ['skills', 'technical skills', 'hobbies', 'achievements', 'languages', 'frameworks','education', 'experience','links']\n",
    "    imp_headings_text = {}\n",
    "    heading_index = -1\n",
    "    heading_text = []\n",
    "    for item in text.split('\\n'):\n",
    "        cur_index = -1\n",
    "        excluded_index = -1\n",
    "        if len(item) < 2 or item.isspace() or item == '\\n':\n",
    "            continue\n",
    "        formatted_text.append(item.strip())\n",
    "        if len(item.strip().split(' ')) == 1:\n",
    "            for heading in imp_headings:\n",
    "                if item.lower().find(heading) != -1:\n",
    "                    cur_index = imp_headings.index(heading)\n",
    "                    break\n",
    "            for heading in excluded_headings:\n",
    "                if item.lower().find(heading) != -1:\n",
    "                    excluded_index = excluded_headings.index(heading)\n",
    "                    break\n",
    "        # if text is containing any of excluded headings\n",
    "        if excluded_index != -1:\n",
    "            if len(heading_text) > 0:\n",
    "                imp_headings_text[imp_headings[heading_index]] = '\\n'.join(str(line) for line in heading_text)\n",
    "            heading_index = -1\n",
    "            heading_text = []\n",
    "\n",
    "        if cur_index == -1:\n",
    "            # if text is part of current imp heading\n",
    "            if heading_index != -1:\n",
    "                heading_text.append(item)\n",
    "\n",
    "        # text contains imp heading\n",
    "        else:\n",
    "            # found new heading\n",
    "            if heading_index == -1:\n",
    "                heading_index = cur_index\n",
    "                heading_text.append(item)\n",
    "            else:\n",
    "                imp_headings_text[imp_headings[heading_index]] = '\\n'.join(str(line) for line in heading_text)\n",
    "                heading_index = cur_index\n",
    "                heading_text = [item]\n",
    "    if heading_index != -1:\n",
    "        imp_headings_text[imp_headings[heading_index]] = '\\n'.join(str(line) for line in heading_text)\n",
    "\n",
    "    \n",
    "    ###functin start\n",
    "    headings_to_skip = ['hobbies', 'achievements', 'education', 'experience', 'languages', 'skills',\n",
    "                        'technical skills','links']\n",
    "    projects_text = []\n",
    "    projects_available = False\n",
    "    string = \"\"\n",
    "    for i in range(0, len(formatted_text)):\n",
    "        if projects_available:\n",
    "            if formatted_text[i].lower() in headings_to_skip:\n",
    "                break\n",
    "            projects_text.append(formatted_text[i])\n",
    "            \n",
    "            string = string + formatted_text[i] + \" \";\n",
    "        elif formatted_text[i].lower().find('project') != -1:\n",
    "            projects_available = True\n",
    "    \n",
    "    return string[:-1]\n",
    "\n",
    "getProjects('C:/Users/yashd/OneDrive/Documents/Github Master/Assessor/Sample Resume/Yash-Dewangan-CV.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
